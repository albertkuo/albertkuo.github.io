---
layout: post
title: "Sample post"
date: 2017-05-03 19:06:00
comments: true
description: "This is a sample post."
keywords: "sample"
category: sample
mathjax: true
tags:
- sample
---

  * This is true under three scenarios:

    - 1) If $X_n \geq 0$ and $X_n \leq X_{n+1}$ for all $n$ (monotone convergence)

    - 2) If $\lvert X_n\rvert \leq M$ for some constant $M$ (bounded convergence)

    - 3) If $\lvert X_n\rvert \leq Y$ for an integrable random variable $Y$, i.e. $E\lvert Y \rvert < \infty$ (dominated convergence)

  * Example (dominated convergence): Consider the probability space $(\Omega, \mathcal{F}, \mu)$. Let $X \geq 0$ be an integrable random variable and define $v(A) = \int_A X d \mu$ for $A \in \mathcal{F}$. To show that $v$ is a measure, a necessary condition is that $v(\cup_{i=1}^\infty A_i) = \sum_{i=1}^\infty v(A_i)$. This is true since

    \begin{align}
    \sum_{i=1}^\infty v(A_i) &= \lim_{n\rightarrow \infty} \sum_{i=1}^n v(A_i) \\\\ 
        &=\lim_{n \rightarrow \infty} \sum_{i=1}^n \int_{A_i} Xd\mu \\\\ 
        &=\lim_{n \rightarrow \infty}\sum_{i=1}^n \int X1_{A_i}d\mu \\\\ 
    \end{align}


$$
\begin{align}
A &= B \\
& = A
\end{align}
$$
* Characteristic Functions

* Continuous Mapping Theorem

* Jensen's Inequality

* Markov's (Chebyshev's) Inequality

* Taylor Series

* Truncating the Sum


